---
title: "eds242_final"
author: Joshua Ferrer-Lozano
date: 12/9/2025
format: html
editor: visual
---


# Environmental Data Bias: Case Studies and Pathways to Justice
# Introduction
Environmental data are often treated as neutral, objective, and “raw.” Yet as scholars across environmental justice, data studies, and Indigenous methodologies have shown, data are always shaped by the contexts in which they are collected, reported, and interpreted. Biases—whether through suppression, measurement choices, deficit framing, sampling gaps, or confounding variables—can profoundly influence how environmental problems are understood and addressed. Recognizing these biases is essential for building more equitable, transparent, and participatory data practices. This project examines five case studies of environmental data bias, each illustrating a distinct type of bias and its consequences for science, policy, and justice. Together, they demonstrate that environmental data justice requires not only technical rigor but also attention to social, cultural, and political contexts.

# Case Descriptions
Archiving Federal Environmental Data (Nost et al., 2024)
The Environmental Data & Governance Initiative (EDGI) documented how the Trump administration deleted Clean Power Plan webpages, calculators, and fact sheets months before formally proposing repeal. This is a clear example of reporting bias and suppression, where inconvenient data were removed from public view. The impact was significant: communities and policymakers lost access to tools that quantified emissions and incentives, undermining transparency and accountability. Archiving efforts like EDGI’s highlight the importance of preserving not only datasets but also their metadata and contextual narratives.

Louisiana Bucket Brigade (Walker et al., 2018; Vera et al., 2019)
In Louisiana, state monitors averaged toxic emissions over 24‑hour periods, masking short‑term spikes in pollution near chemical facilities. Community members responded by developing “air buckets” to capture peak exposures. This case illustrates measurement bias, where methodological choices obscured acute hazards. Official data understated health risks, while community‑generated data revealed the lived realities of fence‑line communities. The Bucket Brigade demonstrates how participatory monitoring can counteract biases and democratize environmental knowledge.

Indigenous Health Statistics (Walter & Suina, 2019)
Indigenous statistics in settler states often emphasize difference, disparity, disadvantage, dysfunction, and deprivation—the so‑called “5D data.” This framing positions Indigenous peoples primarily through deficit narratives, a form of outcome reporting bias and deficit framing bias. The impact is profound: such data reinforce colonial logics and obscure Indigenous lifeworlds of wellness, which include spirituality, language, and community well‑being. Walter and Suina argue for Indigenous quantitative methodologies and data sovereignty to disrupt deficit narratives and ensure data reflect Indigenous priorities and values.

Biodiversity Monitoring (Young et al., 2014)
Global biodiversity datasets disproportionately represent birds and mammals, while insects, fungi, and plants are undercounted. This is a classic case of sampling bias, where charismatic species are privileged in monitoring efforts. The impact is skewed conservation priorities that neglect less visible but ecologically critical organisms. Young and colleagues emphasize the need for interdisciplinary dialogue and more inclusive monitoring strategies that reflect ecosystem complexity and policy relevance.

Biases in Environmental Causal Inference (Konno et al., 2024)
A systematic review identified 121 types of bias relevant to environmental research, including confounding and selection bias. For example, in agricultural studies, management practices may confound relationships between soil moisture, sunlight, and crop yields. Even well‑designed studies can mislead if hidden variables are not accounted for. Konno and colleagues highlight the importance of rigorous critical appraisal tools to identify and mitigate biases in causal inference, ensuring that environmental interventions are based on valid evidence.

# Reflections
These five case studies illustrate that environmental data bias is not simply a technical flaw but a reflection of deeper social, political, and cultural contexts. Each case demonstrates how decisions about what data to collect, how to measure it, and how to report it are shaped by power relations and institutional priorities.

From Nost et al. (2024), we see how political suppression of data undermines transparency and accountability. This resonates with my own experience in Georgia, where language bias limited access to environmental reports. Even when data were technically available, the choice of language shaped who could meaningfully engage with it. Both examples highlight that accessibility is not just about open datasets but about ensuring that communities can interpret and use information.

The Louisiana Bucket Brigade shows how measurement bias can obscure lived realities. Official monitors averaged emissions over long periods, masking acute exposures. In Hawaii, I learned through the practice of “talk story” that technical jargon without relational communication can alienate communities. Just as the Bucket Brigade’s air buckets made data relatable and actionable, “talk story” emphasizes that data must be shared in ways that build trust and resonate with local values.

Walter & Suina (2019) remind us that deficit framing bias can reproduce colonial narratives. Indigenous health statistics often emphasize disparities without reflecting Indigenous lifeworlds of wellness. This connects to my vineyard LiDAR project, where focusing only on quantitative canopy metrics risks ignoring cultural practices of viticulture. Both cases show that data must be situated in broader lifeworlds to avoid reinforcing narrow or harmful narratives.

Young et al. (2014) demonstrate sampling bias in biodiversity monitoring, where charismatic species are overrepresented. This reflects a broader tendency to privilege what is visible or valued by dominant institutions. It raises the question: whose priorities shape data collection? Similarly, in my own work, privileging certain variables (sunlight, soil moisture) without considering management practices risks reproducing sampling bias in agricultural contexts.

Finally, Konno et al. (2024) highlight confounding and selection biases in causal inference. Their systematic review shows that even well‑designed studies can mislead if hidden variables are not accounted for. This reinforces the importance of reproducibility and transparency in my own regression analyses, where vineyard management practices may confound relationships between environmental variables and grape sugar content.

Together, these reflections underscore the importance of frameworks like the CARE Principles and Environmental Data Justice (EDJ). CARE emphasizes collective benefit, authority to control, responsibility, and ethics, ensuring that data practices respect Indigenous sovereignty and community values. EDJ situates data within social and political contexts, challenging extractive logics and deficit narratives. Both frameworks remind us that environmental data are never raw—they are always relational, situated, and shaped by power.

# Solutions
The five case studies demonstrate that environmental data bias arises from multiple sources—political suppression, measurement choices, deficit framing, sampling gaps, and confounding variables. Addressing these biases requires a combination of technical, social, and ethical strategies.

Countering Suppression Bias (Nost et al., 2024): Establish independent archiving initiatives that preserve datasets, metadata, and contextual narratives. Model cards and datasheets can provide transparency about origins, limitations, and intended uses.

Addressing Measurement Bias (Louisiana Bucket Brigade): Incorporate participatory monitoring methods that allow communities to collect data reflecting their lived experiences. Citizen science projects and low‑cost sensors can complement official monitoring.

Disrupting Deficit Framing (Walter & Suina, 2019): Adopt Indigenous quantitative methodologies and apply the CARE Principles to ensure sovereignty and empowerment.

Reducing Sampling Bias (Young et al., 2014): Expand biodiversity monitoring to include underrepresented species and ecosystems. Promote interdisciplinary collaboration to jointly frame research questions.

Mitigating Confounding and Selection Bias (Konno et al., 2024): Use critical appraisal tools to systematically identify and address biases in causal inference. Encourage transparency in methods, reproducibility of analyses, and explicit reporting of confounding variables.

Integrative strategies include combining FAIR + CARE Principles to ensure data are both technically sound and ethically governed, applying Environmental Data Justice to situate data within social and political contexts, and communicating data through culturally resonant practices such as “talk story” or multilingual reporting. These approaches ensure that environmental data are not only accurate but also meaningful, accessible, and just.

# Conclusion
Environmental data bias is inevitable, but it is not insurmountable. By recognizing the diverse forms of bias—suppression, measurement, deficit framing, sampling, and confounding—we can design strategies that make data more transparent, participatory, and equitable. The five case studies presented here demonstrate that environmental data justice requires both technical rigor and social responsibility. Ultimately, data are never raw; they are always cooked with care. The challenge is to ensure that they are cooked in ways that serve communities, respect sovereignty, and advance environmental justice.

# References

Konno, K., Gibbons, J., Lewis, R., & Pullin, A. S. (2024). Potential types of bias when estimating causal effects in environmental research and how to interpret them. Environmental Evidence, 13(1), 1–31. https://doi.org/10.1186/s13750-024-00324-7

Nost, E., Gehrke, G., Vera, L., & Hansen, S. (2024). Why the Environmental Data & Governance Initiative is archiving public environmental data. Patterns, 6(1), 101151. https://doi.org/10.1016/j.patter.2024.101151

Walker, D., Nost, E., Lemelin, A., Lave, R., & Dillon, L. (2018). Practicing environmental data justice: From DataRescue to Data Together. Geo: Geography and Environment, 5(2), e00061. https://doi.org/10.1002/geo2.61

Walter, M., & Suina, M. (2019). Indigenous data, indigenous methodologies

